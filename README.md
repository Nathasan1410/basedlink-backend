# üß† BasedLink AI Node (Verifiable Inference)

> **Powered by EigenLayer & EigenCompute**  
> üîí **Security:** Trusted Execution Environment (TEE)  
> ‚ö° **Performance:** Groq Fallback

This is the **Secure AI Backend** for [BasedLink](https://github.com/Auto-Linkid/Frontend). It provides **Verifiably Authentic** AI generation services, ensuring that the content delivered to the user was generated by the specific model claimed, without hidden prompts or manipulation.

---

## üõ°Ô∏è Architecture: The Trust Layer

We deploy this backend on **EigenCompute**, running inside a **TEE (Trusted Execution Environment)**.

1.  **TEE Security:** The code runs in an encrypted enclave. Not even the node operator can see the active memory or private keys.
2.  **Attestation:** The TEE generates a cryptographic **Quote**, proving the code's integrity.
3.  **Verifiable Inference:** Every AI response is signed by the TEE's private key. The frontend verifies this signature.

### Grant-Based Authentication (Novelty)
Instead of traditional API keys (which are Web2), we use a **Wallet-Based Grant System**:
1.  **User Signs:** The user signs a "Grant" message on the Frontend using their **Smart Wallet**.
2.  **Grant Verification:** This backend receives the signature + wallet address.
3.  **Access Control:** If the signature is valid, the TEE allows the AI request to proceed.
4.  **Benefits:**
    -   No API Key management for users.
    -   Onchain identity tied to AI usage.
    -   Sybil resistance via wallet verification.

---

## üõ†Ô∏è Tech Stack (Backend)

-   **Runtime:** Node.js + Express
-   **Security:** **Eigen AI** (Determinal API)
-   **Infrastructure:** **Docker** (Verifiable Build)
-   **Compute:** **EigenCompute** (GCP Confidential VMs)
-   **AI Models:**
    -   **Primary:** `gpt-oss-120b` (via Eigen TEE)
    -   **Fallback:** `Llama-3-8b` (via **Groq** High-Speed API)
-   **Research:** Tavily API (for topic fact-checking)

---

## üöÄ Deployment

This service is deployed using the **EigenCloud CLI** (`ecloud`).

### 1. Build Verification
We use **Verifiable Builds** to prove the Docker image matches the GitHub source code.

```bash
# Build from Git Source (Public Repo)
ecloud compute app deploy
> Select "Build from git source"
> Repo: https://github.com/Nathasan1410/basedlink-backend
> Commit: [Latest SHA]
```

### 2. Live Endpoint
-   **URL:** `http://34.182.68.249:3000`
-   **Status:** Active on EigenCompute (Sepolia)

---

## üîå API Reference

### `POST /api/generate`

Generates AI content (Topics, Hooks, Body, CTA) with cryptographic proof.

**Headers:**
-   `Content-Type: application/json`

**Body:**
```json
{
  "step": "topics",
  "input": "The future of Web3 gaming",
  "model": "gpt-oss-120b-f16",
  "grantMessage": "Grant message string...",
  "grantSignature": "0x...",
  "walletAddress": "0x..."
}
```

**Response (Success):**
```json
{
  "result": ["Topic 1", "Topic 2", ...],
  "signature": "0x[TEE_SIGNATURE_PROOF]"
}
```
*The `signature` field proves the content came from the secure TEE.*

---

## ‚ö†Ô∏è Resilience (Groq Fallback)
If the TEE is initializing (cold boot) or the User fails to provide a signature, the system automatically falls back to **Groq** to ensure zero downtime.
-   **Log:** `‚ö†Ô∏è Switching to Groq fallback due to AI error`
-   **Result:** Content is generated, but without the TEE signature badge.

---

**BasedLink Backend**  
*Building the Trust Layer for Onchain Content*
